{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import *\n",
    "import dill as pkl\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error as loss_fn\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pdl\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import copy\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn.metrics import zero_one_loss\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import tqdm\n",
    "import warnings\n",
    "import time\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import folktables\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/training_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ducky/Documents/Projects/Diversified-Ensembling-Reproducibility/graphs_requiring_dataset.ipynb Cell 2\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ducky/Documents/Projects/Diversified-Ensembling-Reproducibility/graphs_requiring_dataset.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mdata/training_data.csv\u001b[39;49m\u001b[39m'\u001b[39;49m) \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ducky/Documents/Projects/Diversified-Ensembling-Reproducibility/graphs_requiring_dataset.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mgenfromtxt(\u001b[39m'\u001b[39m\u001b[39mdata/training_labels.csv\u001b[39m\u001b[39m'\u001b[39m, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, dtype \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ducky/Documents/Projects/Diversified-Ensembling-Reproducibility/graphs_requiring_dataset.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m x_val \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mdata/validation_data.csv\u001b[39m\u001b[39m'\u001b[39m) \n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/training_data.csv'"
     ]
    }
   ],
   "source": [
    "x_train = pd.read_csv('data/training_data.csv') \n",
    "y_train = np.genfromtxt('data/training_labels.csv', delimiter=',', dtype = float)\n",
    "x_val = pd.read_csv('data/validation_data.csv') \n",
    "y_val = np.genfromtxt('data/validation_labels.csv', delimiter=',', dtype = float)\n",
    "x_test = pd.read_csv('data/test_data.csv') \n",
    "y_test = np.genfromtxt('data/test_labels.csv', delimiter=',', dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Model Base Regressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "clf = DecisionTreeRegressor(max_depth = 1, random_state = 42)\n",
    "clf.fit(x_train, y_train)\n",
    "team_pdl = pdl.PointerDecisionList(clf, x_train, y_train, x_val, y_val, alpha = 100000, min_group_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Model Base Regressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "global_clf = GradientBoostingRegressor(max_depth=4, n_estimators = 500, random_state = 42)\n",
    "global_clf.fit(x_train, y_train)\n",
    "global_pdl = pdl.PointerDecisionList(global_clf, x_train, y_train, x_val, y_val, alpha = 100000, min_group_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures 2, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update with folder name of teams models. Of the form \"alpha_xyz\" if using comp_alpha_rerun.py or \"teams\" if downloading from dataset\n",
    "pdl_folder = \"\"\n",
    "\n",
    "\n",
    "if pdl_folder:\n",
    "    errors_dict = {}\n",
    "    for i in range(46):\n",
    "        team_pdl = pdl.load_model(f\"{pdl_folder}/teams/{i}/PDL\", x_train, y_train, x_val, y_val)\n",
    "        train_errors = team_pdl.track(x_train, y_train)\n",
    "        val_errors = team_pdl.track(x_val, y_val)\n",
    "        test_errors = team_pdl.track(x_test, y_test)\n",
    "        errors_dict[i] = [train_errors, val_errors, test_errors]\n",
    "\n",
    "    global_pdl = pdl.load_model(f\"{pdl_folder}/global_pdl/PDL\", x_train, y_train, x_val, y_val)\n",
    "    train_errors = global_pdl.track(x_train, y_train)\n",
    "    val_errors = global_pdl.track(x_val, y_val)\n",
    "    test_errors = global_pdl.track(x_test, y_test)\n",
    "    errors_dict[46] = [train_errors, val_errors, test_errors]\n",
    "\n",
    "    max_updates = 0\n",
    "    for i in range(47):\n",
    "        updates = len(errors_dict[i][0])\n",
    "        if updates > max_updates:\n",
    "            max_updates = updates\n",
    "\n",
    "    cp = sns.color_palette(n_colors = 47)\n",
    "\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    x = range(max_updates)\n",
    "    for i in range(47):\n",
    "        y = list(np.sqrt(errors_dict[i][0])) + ([None] * (max_updates - len(errors_dict[i][0])))\n",
    "        if i == 46:\n",
    "            ax = sns.lineplot(x = x, y = y, color = \"black\", label = \"Global Model\")\n",
    "        else:\n",
    "            ax = sns.lineplot(x = x, y = y, color = cp[i], label = f\"Team {i}\")\n",
    "    ax.legend(bbox_to_anchor=(1.02, 1.01), fontsize=8)\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Update Round\")\n",
    "    ax.set_title(\"Team Training Loss over Course of Updates\")\n",
    "    plt.savefig(\"paper_plots/team_train_errors_time.pdf\", format=\"PDF\", bbox_inches='tight')\n",
    "\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    x = range(max_updates)\n",
    "    for i in range(47):\n",
    "        y = list(np.sqrt(errors_dict[i][1])) + ([None] * (max_updates - len(errors_dict[i][0])))\n",
    "        if i == 46:\n",
    "            ax = sns.lineplot(x = x, y = y, color = \"black\", label = \"Global Model\")\n",
    "        else:\n",
    "            ax = sns.lineplot(x = x, y = y, color = cp[i], label = f\"Team {i}\")\n",
    "    ax.legend(bbox_to_anchor=(1.02, 1.01), fontsize=8)\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Update Round\")\n",
    "    ax.set_title(\"Team Validation Loss over Course of Updates\")\n",
    "    plt.savefig(\"paper_plots/team_val_errors_time.pdf\", format=\"PDF\", bbox_inches='tight')\n",
    "\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    x = range(max_updates)\n",
    "    for i in range(47):\n",
    "        y = list(np.sqrt(errors_dict[i][2])) + ([None] * (max_updates - len(errors_dict[i][0])))\n",
    "        if i == 46:\n",
    "            ax = sns.lineplot(x = x, y = y, color = \"black\", label = \"Global Model\")\n",
    "        else:\n",
    "            ax = sns.lineplot(x = x, y = y, color = cp[i], label = f\"Team {i}\")\n",
    "    ax.legend(bbox_to_anchor=(1.02, 1.01), fontsize=8)\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Update Round\")\n",
    "    ax.set_title(\"Team Test Loss over Course of Updates\")\n",
    "    plt.savefig(\"paper_plots/team_test_errors_time.pdf\", format=\"PDF\", bbox_inches='tight')\n",
    "\n",
    "    max_updates = 0\n",
    "    final_test_errors = []\n",
    "    for i in range(47):\n",
    "        final_test_errors.append(errors_dict[i][2][-1])\n",
    "\n",
    "    top_ten = np.argsort(final_test_errors)[0:11]\n",
    "\n",
    "    for i in top_ten:\n",
    "        updates = len(errors_dict[i][0])\n",
    "        if updates > max_updates:\n",
    "            max_updates = updates\n",
    "            \n",
    "    cp = sns.color_palette(n_colors = 47)\n",
    "\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    x = range(max_updates)\n",
    "    for i in top_ten:\n",
    "        y = list(np.sqrt(errors_dict[i][0])) + ([None] * (max_updates - len(errors_dict[i][0])))\n",
    "        if i == 46:\n",
    "            ax = sns.lineplot(x = x, y = y, color = \"black\", label = \"Global Model\")\n",
    "        else:\n",
    "            ax = sns.lineplot(x = x, y = y, color = cp[i], label = f\"Team {i}\")\n",
    "    ax.legend(bbox_to_anchor=(1, 1), fontsize=8)\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Update Round\")\n",
    "    ax.set_title(\"Team Training Loss over Course of Updates (Top 10)\")\n",
    "    plt.savefig(\"paper_plots/team_train_errors_time_top_ten.pdf\", format=\"PDF\")\n",
    "\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    x = range(max_updates)\n",
    "    for i in top_ten:\n",
    "        y = list(np.sqrt(errors_dict[i][1])) + ([None] * (max_updates - len(errors_dict[i][0])))\n",
    "        if i == 46:\n",
    "            ax = sns.lineplot(x = x, y = y, color = \"black\", label = \"Global Model\")\n",
    "        else:\n",
    "            ax = sns.lineplot(x = x, y = y, color = cp[i], label = f\"Team {i}\")\n",
    "    ax.legend(bbox_to_anchor=(1, 1), fontsize=8)\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Update Round\")\n",
    "    ax.set_title(\"Team Validation Loss over Course of Updates (Top 10)\")\n",
    "    plt.savefig(\"paper_plots/team_val_errors_time_top_ten.pdf\", format=\"PDF\")\n",
    "\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    x = range(max_updates)\n",
    "    for i in top_ten:\n",
    "        y = list(np.sqrt(errors_dict[i][2])) + ([None] * (max_updates - len(errors_dict[i][0])))\n",
    "        if i == 46:\n",
    "            ax = sns.lineplot(x = x, y = y, color = \"black\", label = \"Global Model\")\n",
    "        else:\n",
    "            ax = sns.lineplot(x = x, y = y, color = cp[i], label = f\"Team {i}\")\n",
    "    ax.legend(bbox_to_anchor=(1, 1), fontsize=8)\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_xlabel(\"Update Round\")\n",
    "    ax.set_title(\"Team Test Loss over Course of Updates (Top 10)\")\n",
    "    plt.savefig(\"paper_plots/team_test_errors_time_top_ten.pdf\", format=\"PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ducky/Documents/Projects/Diversified-Ensembling-Reproducibility/graphs_requiring_dataset.ipynb Cell 8\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ducky/Documents/Projects/Diversified-Ensembling-Reproducibility/graphs_requiring_dataset.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m log_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mFINAL_PAPER.csv\u001b[39m\u001b[39m\"\u001b[39m, index_col\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnnamed: 0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ducky/Documents/Projects/Diversified-Ensembling-Reproducibility/graphs_requiring_dataset.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m columns \u001b[39m=\u001b[39m x_train\u001b[39m.\u001b[39mcolumns \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ducky/Documents/Projects/Diversified-Ensembling-Reproducibility/graphs_requiring_dataset.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m teams_column_usage \u001b[39m=\u001b[39m {}\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ducky/Documents/Projects/Diversified-Ensembling-Reproducibility/graphs_requiring_dataset.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m team \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m46\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "log_df = pd.read_csv(\"FINAL_PAPER.csv\", index_col=\"Unnamed: 0\")\n",
    "\n",
    "columns = x_train.columns \n",
    "\n",
    "teams_column_usage = {}\n",
    "for team in range(46):\n",
    "    teams_column_usage[team] = {}\n",
    "    data = log_df[log_df[\"TID\"] == float(team)]\n",
    "    for column in columns:\n",
    "       teams_column_usage[team][column] = 0\n",
    "       for index in range(len(data)):\n",
    "           if column in data.iloc[index][\"GrCo\"]:\n",
    "            teams_column_usage[team][column] += 1   \n",
    "\n",
    "team = \"Global\"\n",
    "teams_column_usage[team] = {}\n",
    "for column in columns:\n",
    "  teams_column_usage[team][column] = 0\n",
    "  for index in range(len(log_df)):\n",
    "      try:\n",
    "        if column in log_df[\"GrCo\"][index]:\n",
    "            teams_column_usage[team][column] += 1 \n",
    "      except:\n",
    "         continue\n",
    "      \n",
    "for team in range(46):\n",
    "    data = log_df[log_df[\"TID\"]  == float(team)]\n",
    "    teams_column_usage[team][\"count\"] = (log_df[log_df[\"TID\"] == float(team)][\"GrCo\"] != \"automatic\").sum()\n",
    "teams_column_usage[\"Global\"][\"count\"] = (log_df[\"GrCo\"] != \"automatic\").sum()     \n",
    "\n",
    "teams = []\n",
    "for team in range(46):\n",
    "    team_focus = []\n",
    "    for column in columns:\n",
    "        team_focus.append(teams_column_usage[team][column] / teams_column_usage[team][\"count\"])\n",
    "    teams.append(team_focus)\n",
    "team_focus = []\n",
    "team = \"Global\"\n",
    "for column in columns:\n",
    "    team_focus.append(teams_column_usage[team][column] / teams_column_usage[team][\"count\"])\n",
    "teams.append(team_focus)\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "x_labels = list(range(46))\n",
    "x_labels.append(\"Global\")\n",
    "sns.heatmap(pd.DataFrame(np.array(teams), columns=columns).T,xticklabels=x_labels, yticklabels=columns, cmap=sns.color_palette(\"light:b\", as_cmap=True))\n",
    "plt.savefig(\"paper_plots/feature_usage_heatmap.pdf\", format=\"PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_predictions_array = []\n",
    "for i in range(45):\n",
    "    team_predictions_array.append(np.genfromtxt(f'old_teams/teams/{i}/test_predictions.csv', delimiter=',', dtype = float))\n",
    "team_predictions_array = np.array(team_predictions_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pdl_folder:\n",
    "    team_predictions_array = []\n",
    "    for i in range(45):\n",
    "        team_predictions_array.append(np.genfromtxt(f'{pdl_folder}/teams/{i}/test_predictions.csv', delimiter=',', dtype = float))\n",
    "    team_predictions_array = np.array(team_predictions_array)\n",
    "\n",
    "    global_predictions = np.genfromtxt(f'{pdl_folder}/global_pdl/test_predictions.csv', delimiter=',', dtype = float)\n",
    "\n",
    "    alpha = -100000\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.yscale('log')\n",
    "    for team in [33,21,3,31,39]:\n",
    "        delta = np.abs(global_predictions - team_predictions_array[team])\n",
    "        indices = delta < .0001\n",
    "        delta[indices] = 0\n",
    "        order = np.argsort(delta)\n",
    "        y_ordered = delta[order]\n",
    "        x = range(len(delta))\n",
    "        \n",
    "        ax = sns.scatterplot(x = np.array(x)[0:-1:50], y=y_ordered[0:-1:50], edgecolors=None, linewidth=0, s = 10, label = f\"Global - Team {team}\")\n",
    "\n",
    "    ax.set_ylabel(\"Prediction Difference (Log Scale)\")\n",
    "    ax.set_xlabel(\"Instances\")\n",
    "    ax.set_title(f\"Test Prediction Differences of Global Model with Top 5 Teams\", fontsize = 15)\n",
    "    plt.savefig(\"tmp.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
